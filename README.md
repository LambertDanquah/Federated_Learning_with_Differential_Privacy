# Federated_Learning_with_Differential_Privacy

The main points include 
1. FedAvg was used as the aggregation function for collaborative training of the deep learning model by four (4) clients.
2. TensorFlow Privacy was used to implement differential privacy (DP-Adam, a variant of DP-SGD).
3. XGBoost-generated feature importance was used for Feature Selection and Principal Component Analysis (PCA) was used for dimensionality reduction, contributing to reduction in computational complexity
4. Multi-Layer Perceptron with 4 hidden layers had the lowest computational complexity and highest Mirai botnet attack detection rate.
5. Performance metrics: Accuracy, Precision, Recall, F1 Score, Area Under the Curve, Confusion Matrix, number of FLoating-point OPerations (FLOPs)


# Participated in the OpenMined #30DaysOfFLCode Challenge (finished 16th Jan, 2025)
I read research papers and did some hands-on work in the area of Federated Learning and Privacy-Enhancing Technologies (PETs) for 30 consecutive days. Major topics included
1. Enhancing Users Consent in Federated Learning(https://ieeexplore.ieee.org/document/10664305)
2. Federated Fine-Tuning of LLMs with Private Data (Flower Framework)
3. Efficient Pruning for Machine Learning under Homomorphic Encryption (https://fhe.org/meetups/041-Efficient_Pruning_for_Machine_Learning_under_Homomorphic_Encryption)
4. Concrete ML by Zama - Machine Learning on FHE Encrypted Data (https://www.youtube.com/watch?v=DP_4OBNf3WY)
5. Zero-Knowledge Proofs for Verfiable FHE (https://blog.sunscreen.tech/snarks-shortcomings/)
6. Federated Learning Challenges and Future Directions (https://arxiv.org/pdf/1908.07873)
7. Data minimization and anonymization for privacy enhancement in Federated Learning and Analytics (https://dl.acm.org/doi/pdf/10.1145/3500240)
